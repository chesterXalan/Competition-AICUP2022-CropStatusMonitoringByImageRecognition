{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b16cf8e9-c11e-4816-8e4d-769f4b01224c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a12e782-34ab-4e70-a6ef-17432f822fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_images: (22308, 480, 480, 3)\n",
      "test_images_lst: 22308\n",
      "classes: 33\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = r'..\\dataset\\npz'\n",
    "test_public_images = np.load(Path(dataset_dir, 'test_public_cropped_480x480.npz'))['test_images']\n",
    "test_private_images = np.load(Path(dataset_dir, 'test_private_cropped_480x480.npz'))['test_images']\n",
    "test_images = np.concatenate((test_public_images, test_private_images))\n",
    "print(f'test_images: {test_images.shape}')\n",
    "\n",
    "public_json_file = r'..\\dataset\\test_public.json'\n",
    "with open(public_json_file, 'r') as f:\n",
    "    test_public_images_lst = json.load(f)['test']\n",
    "private_json_file = r'..\\dataset\\test_private.json'\n",
    "with open(private_json_file, 'r') as f:\n",
    "    test_private_images_lst = json.load(f)['test']\n",
    "test_images_lst = test_public_images_lst+test_private_images_lst\n",
    "print(f'test_images_lst: {len(test_images_lst)}')\n",
    "\n",
    "cls_file = r'..\\dataset\\classes.txt'\n",
    "with open(cls_file, 'r') as f:\n",
    "    classes = [line.rstrip() for line in f.readlines()]\n",
    "print(f'classes: {len(classes)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66510425-e2fc-423b-9585-80c0c20b73e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = {'ImageNet': transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                              std=[0.229, 0.224, 0.225]),\n",
    "             'TestData': transforms.Normalize(mean=[0.427, 0.458, 0.374],\n",
    "                                              std=[0.224, 0.221, 0.247])}\n",
    "transform = nn.Sequential(\n",
    "    normalize['ImageNet']\n",
    ")\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, x):\n",
    "        self.image = x\n",
    "        \n",
    "    def __getitem__(self, index): \n",
    "        image = np.transpose(self.image[index], (2, 0, 1))\n",
    "        image = torch.tensor(image, dtype=torch.float32).div_(255).cuda()\n",
    "        image = transform(image)\n",
    "        \n",
    "        return image\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24916dcf-a62e-4d98-9ac9-e213ce508ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "test_data = DataLoader(MyDataset(test_images), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "420f7eb5-e6d1-4b2f-b2d8-f0219ba2ec58",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = 'efficientnetv2_s_20221213_132051-last'\n",
    "model_path = Path('models', model_name+'.pth')\n",
    "model = torch.load(model_path).cuda()\n",
    "#print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95921c99-7024-4773-9401-cca24dd9d5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test: 100%|███████████████████████████████████████████████████████████████████████| 349/349 [01:43<00:00,  3.36batch/s]\n"
     ]
    }
   ],
   "source": [
    "preds_lst = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_data, unit='batch', desc='test: '):\n",
    "        images = batch\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "        preds_lst.append(preds.cpu().tolist())\n",
    "\n",
    "pred_lst = [pred for preds in preds_lst for pred in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a733fb77-50c8-4215-bb95-2e3e46cd78ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = {'filename': test_images_lst, 'label': [classes[pred] for pred in pred_lst]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "csv_dir = 'test_results'\n",
    "csv_file = Path(csv_dir, model_name+'-pub_pri.csv')\n",
    "df.to_csv(csv_file, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98aa8c0e-d325-41fd-b66c-0d9e8b573aa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-1-13",
   "language": "python",
   "name": "pytorch-1-13"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
